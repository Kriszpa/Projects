{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install('seaborn')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.preprocessing import PolynomialFeatures",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "filepath = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod2.csv'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "await download(filepath, \"laptops.csv\")\nfile_name=\"laptops.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name, header=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Divide the dataset into x_data and y_data parameters\ny_data = df['Price']\nx_data = df.drop('Price',axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Split the data set into training and testing subests such that you reserve 10% of the data set for testing purposes.\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)\nprint(\"number of test samples :\", x_test.shape[0])\nprint(\"number of training samples:\",x_train.shape[0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Create a single variable linear regression model using \"CPU_frequency\" parameter. \nlre=LinearRegression()\nlre.fit(x_train[['CPU_frequency']], y_train)\nprint(lre.score(x_test[['CPU_frequency']], y_test))\nprint(lre.score(x_train[['CPU_frequency']], y_train))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Run a 4-fold cross validation on the model and print the mean value of R^2 score along with its standard deviation.\nRcross = cross_val_score(lre, x_data[['CPU_frequency']], y_data, cv=4)\nprint(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Split the data set into training and testing components again, this time reserving 50% of the data set for testing.\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.5, random_state=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "lre = LinearRegression()\nRsqu_test = []\norder = [1, 2, 3, 4, 5]\nfor n in order:\n    pr = PolynomialFeatures(degree=n)\n    x_train_pr = pr.fit_transform(x_train[['CPU_frequency']])\n    x_test_pr = pr.fit_transform(x_test[['CPU_frequency']])    \n    lre.fit(x_train_pr, y_train)\n    Rsqu_test.append(lre.score(x_test_pr, y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Plot the values of R^2 scores against the order. Note the point where the score drops.\nplt.plot(order, Rsqu_test)\nplt.xlabel('order')\nplt.ylabel('R^2')\nplt.title('R^2 Using Test Data')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Create a polynomial feature model that uses all these parameters with degree=2\nx_train_pr=pr.fit_transform(x_train[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']])\nx_test_pr=pr.fit_transform(x_test[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Create a Ridge Regression model and evaluate it using values of the hyperparameter alpha ranging from 0.001 to 1 with increments of 0.001. Create a list of all Ridge Regression R^2 scores for training and testing data.\nRsqu_test = []\nRsqu_train = []\nAlpha = np.arange(0.001,1,0.001)\npbar = tqdm(Alpha)\n\nfor alpha in pbar:\n    RigeModel = Ridge(alpha=alpha) \n    RigeModel.fit(x_train_pr, y_train)\n    test_score, train_score = RigeModel.score(x_test_pr, y_test), RigeModel.score(x_train_pr, y_train)\n    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n    Rsqu_test.append(test_score)\n    Rsqu_train.append(train_score)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Plot the R^2 values for training and testing sets with respect to the value of alpha\nplt.figure(figsize=(10, 6))  \nplt.plot(Alpha, Rsqu_test, label='validation data')\nplt.plot(Alpha, Rsqu_train, 'r', label='training Data')\nplt.xlabel('alpha')\nplt.ylabel('R^2')\nplt.ylim(0, 1)\nplt.legend()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Using the raw data and the same set of features as used above, use GridSearchCV to identify the value of alpha for which the model performs best. Assume the set of alpha values to be used as\n#{0.0001, 0.001, 0.01, 0.1, 1, 10}\nparameters1= [{'alpha': [0.0001,0.001,0.01, 0.1, 1, 10]}]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Create a Ridge instance and run Grid Search using a 4 fold cross validation.\nRR=Ridge()\nGrid1 = GridSearchCV(RR, parameters1,cv=4)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Fit the Grid Search to the training data.\nGrid1.fit(x_train[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']], y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Print the R^2 score for the test data using the estimator that uses the derived optimum value of alpha.\nBestRR=Grid1.best_estimator_\nprint(BestRR.score(x_test[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core','OS','GPU','Category']], y_test))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}